AI & Ethics
(Portfolio Section – English)
1. Introduction: Why AI Ethics Matters
Artificial Intelligence is increasingly embedded in everyday life — from healthcare and finance to hiring, housing, and public administration.
Ethical principles ensure that AI systems:
• 	respect human rights
• 	avoid discrimination
• 	remain transparent and accountable
• 	support, rather than undermine, social trust
AI ethics is not optional; it is a core requirement for responsible technology.

2. Key Ethical Principles in AI
A) Fairness & Non‑Discrimination
AI systems must not reinforce or amplify biases related to:
• 	gender
• 	ethnicity
• 	age
• 	disability
• 	socioeconomic status
Fairness requires diverse datasets, bias detection, and continuous monitoring.

B) Transparency & Explainability
Users should understand:
• 	how an AI system makes decisions
• 	what data it uses
• 	what limitations it has
Explainability builds trust and allows meaningful oversight.

C) Accountability
Clear responsibility must exist for:
• 	data quality
• 	model decisions
• 	system failures
• 	harm prevention
Accountability ensures that AI is not a “black box without consequences”.

D) Privacy & Data Protection
AI must respect:
• 	data minimisation
• 	secure storage
• 	informed consent
• 	user autonomy
Ethical AI avoids unnecessary data collection and protects sensitive information.

E) Safety & Reliability
AI systems must be:
• 	robust
• 	predictable
• 	resistant to manipulation
• 	tested against misuse
Safety is especially critical in healthcare, finance, and public services.

F) Human Oversight
AI should support, not replace, human judgment.
Humans must remain:
• 	in control
• 	able to override decisions
• 	responsible for outcomes
This prevents automation from undermining human rights or democratic processes.

3. Ethical Risks in AI Systems
• 	Bias & discrimination through skewed datasets
• 	Hallucinations (fabricated facts)
• 	Opaque decision‑making
• 	Over‑reliance on automation
• 	Manipulation & misinformation
• 	Surveillance misuse
• 	Lack of recourse for affected individuals
These risks require continuous evaluation and governance.

4. Ethical AI in Practice
A) Governance & Guidelines
Organisations implement:
• 	AI ethics boards
• 	risk assessments
• 	model audits
• 	transparency reports
B) Technical Measures
• 	bias detection tools
• 	explainable AI methods
• 	differential privacy
• 	robust model testing
C) Human‑Centered Design
• 	inclusive datasets
• 	user feedback loops
• 	accessibility standards
Ethical AI is both a technical and social responsibility.

5. My Competence in AI & Ethics
In my portfolio, this topic demonstrates my ability to:
• 	evaluate AI systems critically
• 	identify ethical risks (e.g., bias, hallucinations, misinformation)
• 	understand regulatory and societal expectations
• 	apply ethical principles to real‑world AI use cases
• 	communicate complex issues clearly and responsibly
This strengthens my profile in AI literacy, responsible use of technology, and quality assurance.
